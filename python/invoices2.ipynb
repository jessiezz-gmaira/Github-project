{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(r'C:\\Users\\GisselleMaira\\test.ini')\n",
    "\n",
    "import json\n",
    "import os\n",
    "import urllib.request\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import date\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "import datetime\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.relative_locator import locate_with\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "# from bs4 import BeautifulSoup\n",
    "import shutil\n",
    "import glob\n",
    "import os.path\n",
    "import os\n",
    "import time\n",
    "import configparser\n",
    "import win32com.client\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import xlrd\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-01 2021-12-01\n"
     ]
    }
   ],
   "source": [
    "today = date.today()\n",
    "prev_4month = today - relativedelta(months=4)\n",
    "prev_4month = prev_4month.replace(day=1)\n",
    "\n",
    "\n",
    "#get dynamic date for last 3 months\n",
    "today = date.today()\n",
    "\n",
    "tgt = datetime.datetime(2021, 1, 1)\n",
    "d1 = tgt.strftime(\"%Y-%m-%d\")\n",
    "d2 = prev_4month\n",
    "# curr_month = today.replace(day=1)\n",
    "# d2 = curr_month.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "start = today + timedelta(days=-today.weekday(), weeks=-18)\n",
    "\n",
    "\n",
    "\n",
    "acct = config['api']['account']\n",
    "token = config['api']['token']\n",
    "\n",
    "print(d1, d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload={}\n",
    "headers = {\n",
    "  'Harvest-Account-Id': acct,\n",
    "  'Authorization': token\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull invoice data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting https://api.harvestapp.com/v2/invoices?from=2021-01-01&page=1\n",
      "Requesting https://api.harvestapp.com/v2/invoices?from=2021-01-01&page=2&per_page=100&ref=next\n"
     ]
    }
   ],
   "source": [
    "url = f\"https://api.harvestapp.com/v2/invoices?from={d1}&page=1\"\n",
    "\n",
    "invoices = []\n",
    "\n",
    "while url:\n",
    "    print('Requesting', url)\n",
    "    \n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload).text\n",
    "    data_json  = json.loads(response)['invoices']\n",
    "    invoices.extend(data_json)\n",
    "    \n",
    "    url = json.loads(response)['links']['next']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "items = pd.json_normalize(invoices, meta = ['number'], record_path = ['line_items'])\n",
    "totals = pd.json_normalize(invoices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_df = pd.merge(totals, items, on = 'number', how= 'left')\n",
    "\n",
    "invoice_df.columns = invoice_df.columns.str.replace('.', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_df.rename(columns = {'number': 'invoice_num', 'kind': 'services_provided', 'amount_y': 'ttl_item_amount', \\\n",
    "                  'amount_x': 'invoice_amt', 'id_x': 'invoice_id'}, inplace=True)\n",
    "invoice_df.drop(columns=['client_key', 'purchase_order', 'tax', 'tax_amount', 'tax2', 'tax2_amount',\\\n",
    "                        'discount', 'notes', 'recurring_invoice_id', 'created_at', 'updated_at',  'currency',\\\n",
    "                         'estimate', 'retainer', 'id_y', 'paid_at', 'creator_name', 'creator_id', 'taxed', \\\n",
    "                         'taxed2', 'line_items', 'project'], axis=1, inplace = True)\n",
    "\n",
    "# summary table\n",
    "\n",
    "# invoice_df[['client_name', 'project_name', 'project_code', 'period_end', 'subject', 'invoice_num', \\\n",
    "#             'invoice_amt', 'state']].drop_duplicates()\n",
    "# invoice_df.to_excel(r'C:\\Users\\GisselleMaira\\Desktop\\invoices.xlsx', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_df['user_name'] = invoice_df['description'].str.split(':', expand=True)[1].str.split('(', expand=True)[0]\n",
    "invoice_df.rename(columns = {'unit_price': 'hourly_rate'}, inplace = True)\n",
    "\n",
    "rate_card = invoice_df.drop_duplicates(subset=['user_name', 'project_name', 'hourly_rate'] )[['user_name', 'project_name', 'hourly_rate']]\n",
    "rate_card = rate_card.dropna(axis=0, subset=['project_name', 'user_name']).sort_values(['project_name', 'user_name']).reset_index()\n",
    "\n",
    "rate_card.drop('index',1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_card.user_name = rate_card.user_name.str.strip()\n",
    "rate_card = rate_card.loc[~rate_card.user_name.isin (['Credit Strategy Assessment', 'Client work', 'RDAR Reporting', 'Discount for hours concession represented above'])]\n",
    "rate_card = rate_card.loc[~rate_card.project_name.isin (['Senior Leadership Training'])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull time entries (recent only) and assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&per_page=100&page=1\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=2&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=3&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=4&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=5&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=6&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=7&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=8&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=9&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=10&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=11&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=12&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=13&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=14&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=15&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=16&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=17&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=18&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=19&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=20&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=21&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=22&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=23&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=24&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=25&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=26&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=27&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=28&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=29&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=30&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=31&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=32&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=33&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=34&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=35&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=36&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=37&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=38&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=39&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=40&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=41&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=42&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=43&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=44&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=45&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=46&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=47&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=48&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=49&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=50&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=51&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=52&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=53&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=54&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/time_entries?from=2021-12-01&page=55&per_page=100&ref=next\n"
     ]
    }
   ],
   "source": [
    "url = f\"https://api.harvestapp.com/v2/time_entries?from={d2}&per_page=100&page=1\"\n",
    "all_data = []\n",
    "\n",
    "while url:\n",
    "    print('Requesting', url)\n",
    "    \n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload).text\n",
    "    data_json  = json.loads(response)['time_entries']\n",
    "    all_data.extend(data_json)\n",
    "    \n",
    "    url = json.loads(response)['links']['next']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df = pd.json_normalize(all_data,max_level=1)\n",
    "item_df.columns = item_df.columns.str.replace('.', '_')\n",
    "# item_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting https://api.harvestapp.com/v2/user_assignments?page=1&per_page=100\n",
      "Requesting https://api.harvestapp.com/v2/user_assignments?page=2&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/user_assignments?page=3&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/user_assignments?page=4&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/user_assignments?page=5&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/user_assignments?page=6&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/user_assignments?page=7&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/user_assignments?page=8&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/user_assignments?page=9&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/user_assignments?page=10&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/user_assignments?page=11&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/user_assignments?page=12&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/user_assignments?page=13&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/user_assignments?page=14&per_page=100&ref=next\n",
      "Requesting https://api.harvestapp.com/v2/user_assignments?page=15&per_page=100&ref=next\n"
     ]
    }
   ],
   "source": [
    "url_assign = f\"https://api.harvestapp.com/v2/user_assignments?page=1&per_page=100\"\n",
    "all_data_assign = []\n",
    "\n",
    "while url_assign:\n",
    "    print('Requesting', url_assign)\n",
    "    \n",
    "    response_assign = requests.request(\"GET\", url_assign, headers=headers, data=payload).text\n",
    "    data_json_assign  = json.loads(response_assign)['user_assignments']\n",
    "    all_data_assign.extend(data_json_assign)\n",
    "    \n",
    "    url_assign = json.loads(response_assign)['links']['next']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_df = pd.json_normalize(all_data_assign,max_level=1)\n",
    "assign_df.columns = assign_df.columns.str.replace('.', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_df = assign_df[['project_id', 'project_name', 'project_code', 'user_id', 'user_name', 'hourly_rate']]\n",
    "item_df = item_df[['spent_date','user_id', 'user_name','client_id', 'client_name', 'rounded_hours', 'project_id','project_name',\\\n",
    "            'project_code', 'task_id', 'task_name', 'notes', 'is_closed', 'is_billed', 'billable',\n",
    "            'budgeted', 'invoice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_merge = pd.merge(item_df, assign_df, on=['user_id', 'user_name','project_id', 'project_name', 'project_code'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get user roles and emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting https://api.harvestapp.com/v2/users?page=1&per_page=100\n",
      "Requesting https://api.harvestapp.com/v2/users?page=2&per_page=100&ref=next\n"
     ]
    }
   ],
   "source": [
    "URL_users = f\"https://api.harvestapp.com/v2/users?page=1&per_page=100\"\n",
    "all_users = []\n",
    "\n",
    "while URL_users:\n",
    "    print('Requesting', URL_users)\n",
    "    \n",
    "    response_users = requests.request(\"GET\", URL_users, headers=headers, data=payload).text\n",
    "    data_json_users  = json.loads(response_users)['users']\n",
    "    all_users.extend(data_json_users)\n",
    "    \n",
    "    URL_users = json.loads(response_users)['links']['next']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users = pd.json_normalize(all_users,max_level=1)\n",
    "users2 = users.explode('roles')[['id', 'first_name', 'last_name','is_project_manager', 'is_active', 'default_hourly_rate', 'cost_rate', 'roles']]\n",
    "\n",
    "# isolate emails and filter out FP - they can have multiple assignments\n",
    "# FPemail = users2[users2['roles'].isin(['Flying Phase'])]['email']\n",
    "# nonFP = users2[~users2.email.isin(FPemail)]\n",
    "# FP = users2[users2.email.isin(FPemail)]\n",
    "\n",
    "# get advisor/consultants/ principals.\n",
    "# FP2 = FP[FP['roles'].isin(['Advisor', 'Consultant', 'Principal'])][['id', 'first_name', 'last_name', 'email', 'default_hourly_rate', 'cost_rate', 'roles']]\n",
    "# BU2 = users2[users2['roles'].isin(['Flying Phase'])][['id', 'email', 'roles']]\n",
    "# FP3 = pd.merge(FP2, BU2 , on = ['id', 'email'], how='left')\n",
    "\n",
    "# nonFP2 = nonFP[nonFP['roles'].isin(['Advisor', 'Consultant', 'Principal'])][['id', 'first_name', 'last_name', 'email', 'default_hourly_rate', 'cost_rate', 'roles']]\n",
    "# BU1 = users2[users2['roles'].isin(['CCOM', 'Risk', 'Data and Analytics'])][['id', 'email', 'roles']]\n",
    "# nonFP3 = pd.merge(nonFP2, BU1 , on = ['id', 'email'], how='left')\n",
    "\n",
    "users2A = users2[users2['roles'].isin(['Advisor', 'Consultant', 'Principal'])]\n",
    "users2B = users2[users2['roles'].isin(['Risk', 'Flying Phase', 'CCOM', 'Data and Analytics'])][['id', 'roles']]\n",
    "all_users2 = pd.merge(users2A, users2B , on = ['id'], how='left')\n",
    "\n",
    "all_users2.rename(columns={'roles_x': 'role', 'roles_y': 'BusUnit'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GisselleMaira\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n",
      "<ipython-input-18-c7e454aabada>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  users3['user_name'] = users3['first_name'] + ' ' + users3['last_name']\n",
      "C:\\Users\\GisselleMaira\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "users3 = all_users2[[ 'id', 'role', 'BusUnit', 'first_name', 'last_name']] \n",
    "users3.rename({'id':'user_id'}, axis=1, inplace=True)\n",
    "\n",
    "users3['user_name'] = users3['first_name'] + ' ' + users3['last_name']\n",
    "users3.drop(['first_name', 'last_name'],1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GisselleMaira\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    }
   ],
   "source": [
    "users3.loc[users3['user_name'].isin([\n",
    "    'Brett Ludden', 'Adam Searles', 'Parag Patwardhan', 'Kim Poremski',\n",
    "    'Kevin Baquero', 'Parker Barouch', 'Jim Euchner', 'Shekhar Nagendra'\n",
    "]), ['BusUnit']] = 'Data and Analytics'\n",
    "\n",
    "\n",
    "users3.loc[users3['user_name'].isin(['Christine Dodson', 'Lena Sapia', 'Anthony Gibbs']),\n",
    "              ['BusUnit']] = 'Risk'\n",
    "\n",
    "users3.loc[users3['user_name'].\n",
    "              isin(['Keith Schleicher', 'Sunil Kumar Shambulingaiah', 'Chris Landrum', 'Dana Bennett',\n",
    "                   'Mark Schuler', 'Kristina Schneider', 'Kenny Martin', 'Erin Clark', 'Jeff Nelson',\n",
    "                   'Stuart Williams', 'Greg Marcel', 'Robert Johnson', 'Rachelle Peay', 'Micah Dalton',\n",
    "                   'Brian Eugley', 'Daniel Shao', 'Matt Borgard', 'Victoria Dlugosz', 'Jeri Mulholland', \n",
    "                   'Terrell Sanders', 'Jeff Brantley', 'Jaime Guzman', 'Samantha Bourne', 'Dave Critchley',\n",
    "                   'Philip Paige', 'Sunil Shambulingaiah']),\n",
    "              ['BusUnit']] = 'Flying Phase'\n",
    "\n",
    "users3.loc[users3['user_name'].isin(\n",
    "    ['Jeff Marshall', 'Scott Hamilton', 'Scott Summers', 'Deb Hollowell', 'Aloma Holsten', 'Ken Roberts']),\n",
    "              ['BusUnit']] = 'CCOM'\n",
    "\n",
    "# users3[users3['BusUnit'].isnull()].sort_values(by=['user_name'])\n",
    "# users3[users3['BusUnit'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merge_all = pd.merge(assign_merge, users3, on = ['user_id', 'user_name'], how='left')\n",
    "merge_all['spent_date'] = pd.to_datetime(merge_all['spent_date']) \n",
    "merge_all['wk_start'] = merge_all['spent_date'] - pd.TimedeltaIndex(merge_all.spent_date.dt.dayofweek,unit='d') \n",
    "\n",
    "merge_all['month'] = merge_all['spent_date'].to_numpy().astype('datetime64[M]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_df['user_name'] = invoice_df['user_name'].str.strip()\n",
    "\n",
    "rate_card = invoice_df.drop_duplicates(\n",
    "    subset=['user_name', 'project_name', 'hourly_rate'])[[\n",
    "        'user_name', 'project_name', 'hourly_rate'\n",
    "    ]]\n",
    "rate_card = rate_card.dropna(axis=0,\n",
    "                             subset=['project_name', 'user_name']).sort_values(\n",
    "                                 ['project_name', 'user_name']).reset_index()\n",
    "rate_card.drop(['index'], 1, inplace=True)\n",
    "# dfmi.loc[:, ('one', 'second')]\n",
    "rate_card.loc[rate_card.user_name == 'Sunil Kumar Shambulingaiah', 'user_name'] = 'Sunil Shambulingaiah'\n",
    "\n",
    "rate_cd = pd.merge(rate_card, users3, on='user_name', how='left')\n",
    "# rate_cd.loc[rate_cd.user_name == 'Sunil Shambulingaiah']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge time entries and invoices monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_df.rename(columns = {'quantity': 'hours', 'ttl_item_amount' : 'billable_amt'}, inplace =True)\n",
    "\n",
    "merge_all.rename(columns = {'rounded_hours': 'hours'}, inplace = True)\n",
    "merge_all['billable_amt'] = merge_all['hourly_rate']*merge_all['hours']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_df['month'] = pd.to_datetime(invoice_df['issue_date']).dt.floor('d') - pd.offsets.MonthBegin(1)\n",
    "\n",
    "describe = invoice_df['description'].str.split(':', expand = True)[1]\n",
    "invoice_df['user_name'] = describe.str.split(\"(\", expand = True)[0]\n",
    "# merge_all = pd.merge(assign_merge, users3, on = 'user_id', how='left')\n",
    "# rate_cd[rate_cd.BusUnit.isnull()]\n",
    "invoice_df.user_name = invoice_df['user_name'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_df.loc[invoice_df['user_name'] == 'Sunil Kumar Shambulingaiah', 'user_name'] = 'Sunil Shambulingaiah'\n",
    "\n",
    "invoices = pd.merge(invoice_df, rate_cd, on = ['user_name','project_name', 'hourly_rate'], how='left')\n",
    "\n",
    "invoice2 = invoices.assign(task_name = '', billable = True, spent_date = '')\n",
    "invoice2 = invoice2[invoice2['state'] != 'draft']\n",
    "\n",
    "timesheet = merge_all.assign(invoice_num = '' , invoice_amt = '', discount_amount = '', subject = '',\\\n",
    "                state = 'time_entries', issue_date = '', services_provided = '', description = '')\n",
    "\n",
    "# Get last invoice date\n",
    "max_date_inv = max(pd.to_datetime(invoice2['issue_date'])) + timedelta(days=1)\n",
    "b4_this_week = today - timedelta(today.weekday()+ 1)\n",
    "this_month = today.replace(day=1)\n",
    "timesheet['spent_date'] = pd.to_datetime(timesheet['spent_date'] )\n",
    "\n",
    "# only take this month's times up to current week for financial tracker\n",
    "timesheet2 = timesheet.loc[(timesheet['spent_date'] >= pd.to_datetime(this_month))]\n",
    "timesheet2 = timesheet2.loc[(timesheet['spent_date'] <= pd.to_datetime(b4_this_week))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesheet2 = timesheet2[[\n",
    "    'client_name', 'project_name', 'project_code', 'month', 'user_name',\n",
    "    'hours', 'hourly_rate', 'billable_amt', 'billable', 'role', 'BusUnit',\n",
    "    'task_name', 'invoice_num', 'invoice_amt', 'discount_amount', 'subject',\n",
    "    'state', 'issue_date', 'services_provided', 'description'\n",
    "]]\n",
    "\n",
    "invoice2 = invoice2[[\n",
    "    'client_name', 'project_name', 'project_code', 'month', 'user_name',\n",
    "    'hours', 'hourly_rate', 'billable_amt', 'billable', 'role', 'BusUnit',\n",
    "    'task_name', 'invoice_num', 'invoice_amt', 'discount_amount', 'subject',\n",
    "    'state', 'issue_date', 'services_provided', 'description'\n",
    "]]\n",
    "invoice2.user_name = invoice2.loc[:, 'user_name'].str.strip()\n",
    "time_entries = pd.concat([timesheet2, invoice2])\n",
    "\n",
    "# missing items check\n",
    "# time_entries.loc[time_entries.BusUnit.isnull()& time_entries.user_name.isnull(),'description'].unique()\n",
    "# users3[users3['BusUnit'].isnull()]\n",
    "\n",
    "time_entries.loc[time_entries.billable == False, 'billable_amt'] = 0\n",
    "\n",
    "time_entries.to_excel(r'C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\DashboardData\\time_entries.xlsx', index = False)\n",
    "\n",
    "# time_entries.loc[(time_entries.project_name == 'CCO Automation') & (time_entries.month == '2021-12-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Archive(name):\n",
    "    path = r'C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\DashboardData'\n",
    "    dt = str(datetime.datetime.now().date()).replace('-','_')\n",
    "    og = path  + '\\\\' + name + '.xlsx'\n",
    "    new = path + '\\\\Archive\\\\' + name + dt + '.xlsx'\n",
    "    shutil.copy2(og,new)\n",
    "\n",
    "Archive('time_entries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Forecast data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape forecast data from Harvest Forecast\n",
    "config = configparser.ConfigParser()\n",
    "config.read(r'C:\\Users\\GisselleMaira\\test.ini')\n",
    "\n",
    "user = config['harvest']['email']\n",
    "pswd = config['harvest']['pswd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2)\n",
    "driver.get(\"https://id.getharvest.com/harvest/sign_in\")\n",
    "#driver.current_url\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = driver.find_element(By.ID, \"email\")\n",
    "pwd = driver.find_element(By.ID, \"password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "email.click()\n",
    "email.send_keys(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd.click()\n",
    "# pwd.sleep(5)\n",
    "pwd.send_keys(pswd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = driver.find_element(By.ID, \"log-in\")\n",
    "submit.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"#forecast-accounts > li > a\"}\n  (Session info: chrome=97.0.4692.71)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x007BE713+2549523]\n\tOrdinal0 [0x007572D1+2126545]\n\tOrdinal0 [0x00652C88+1059976]\n\tOrdinal0 [0x0067E24E+1237582]\n\tOrdinal0 [0x0067E44B+1238091]\n\tOrdinal0 [0x006A9002+1413122]\n\tOrdinal0 [0x00697914+1341716]\n\tOrdinal0 [0x006A73AA+1405866]\n\tOrdinal0 [0x00697736+1341238]\n\tOrdinal0 [0x006734E6+1193190]\n\tOrdinal0 [0x00674376+1196918]\n\tGetHandleVerifier [0x00959742+1627410]\n\tGetHandleVerifier [0x00A0A93C+2352908]\n\tGetHandleVerifier [0x00852AE1+551089]\n\tGetHandleVerifier [0x00851B03+547027]\n\tOrdinal0 [0x0075CBEE+2149358]\n\tOrdinal0 [0x00760F18+2166552]\n\tOrdinal0 [0x00761060+2166880]\n\tOrdinal0 [0x0076AC60+2206816]\n\tBaseThreadInitThunk [0x7734FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77497A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77497A6E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-8e9003a91480>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfrcst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"#forecast-accounts > li > a\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfrcst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m   1242\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1244\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m   1245\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1246\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    426\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"#forecast-accounts > li > a\"}\n  (Session info: chrome=97.0.4692.71)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x007BE713+2549523]\n\tOrdinal0 [0x007572D1+2126545]\n\tOrdinal0 [0x00652C88+1059976]\n\tOrdinal0 [0x0067E24E+1237582]\n\tOrdinal0 [0x0067E44B+1238091]\n\tOrdinal0 [0x006A9002+1413122]\n\tOrdinal0 [0x00697914+1341716]\n\tOrdinal0 [0x006A73AA+1405866]\n\tOrdinal0 [0x00697736+1341238]\n\tOrdinal0 [0x006734E6+1193190]\n\tOrdinal0 [0x00674376+1196918]\n\tGetHandleVerifier [0x00959742+1627410]\n\tGetHandleVerifier [0x00A0A93C+2352908]\n\tGetHandleVerifier [0x00852AE1+551089]\n\tGetHandleVerifier [0x00851B03+547027]\n\tOrdinal0 [0x0075CBEE+2149358]\n\tOrdinal0 [0x00760F18+2166552]\n\tOrdinal0 [0x00761060+2166880]\n\tOrdinal0 [0x0076AC60+2206816]\n\tBaseThreadInitThunk [0x7734FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77497A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77497A6E+238]\n"
     ]
    }
   ],
   "source": [
    "frcst = driver.find_element(By.CSS_SELECTOR, \"#forecast-accounts > li > a\")\n",
    "frcst.click()\n",
    "time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to reports page\n",
    "export = 'https://forecastapp.com/1508320/export'\n",
    "driver.get(export)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select time frame\n",
    "tm_rng = driver.find_element(By.CSS_SELECTOR, \".input-appearance.ember-view\")\n",
    "tm_rng.click()\n",
    "\n",
    "# start with weekly view of this month\n",
    "tm_rng.send_keys(Keys.ARROW_DOWN) \n",
    "\n",
    "tm_rng.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download\n",
    "# driver.find_element_by_class_name(\"button\").click()\n",
    "\n",
    "driver.find_element(By.CLASS_NAME, \"button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'C:\\Users\\GisselleMaira\\Downloads'\n",
    "file_type = '\\*csv'\n",
    "files = glob.glob(folder_path + file_type)\n",
    "max_file = max(files, key=os.path.getctime)\n",
    "#print (max_file)\n",
    "\n",
    "folder_path2 = r'C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\DashboardData'\n",
    "proj_file = folder_path2 + '\\\\project_weekly.csv'\n",
    "\n",
    "shutil.move(max_file, proj_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch to monthly\n",
    "driver.find_element(By.CSS_SELECTOR, \"div:nth-child(4) > div > label:nth-child(2)\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select time frame\n",
    "tm_rng = driver.find_element(By.CSS_SELECTOR, \".input-appearance.ember-view\")\n",
    "tm_rng.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 6 months\n",
    "tm_rng.send_keys(Keys.ARROW_DOWN) # 3 month\n",
    "tm_rng.send_keys(Keys.ARROW_DOWN) # 6 month\n",
    "# tm_rng.send_keys(Keys.ARROW_DOWN) #this year\n",
    "# tm_rng.send_keys(Keys.ARROW_DOWN) # Custom\n",
    "tm_rng.click()\n",
    "\n",
    "# download\n",
    "# driver.find_element_by_class_name(\"button\").click()\n",
    "driver.find_element(By.CLASS_NAME, \"button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'C:\\Users\\GisselleMaira\\Downloads'\n",
    "file_type = '\\*csv'\n",
    "files = glob.glob(folder_path + file_type)\n",
    "max_file = max(files, key=os.path.getctime)\n",
    "#print (max_file)\n",
    "\n",
    "# folder_path2 = r'C:\\Users\\GisselleMaira\\Desktop'\n",
    "proj_file = folder_path2 + '\\\\project_monthly.csv'\n",
    "\n",
    "shutil.move(max_file, proj_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch back to weekly\n",
    "driver.find_element(By.CSS_SELECTOR, \"div:nth-child(4) > div > label:nth-child(1)\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select time frame\n",
    "tm_rng = driver.find_element(By.CSS_SELECTOR, \".input-appearance.ember-view\")\n",
    "tm_rng.click()\n",
    "\n",
    "tm_rng.send_keys(Keys.ARROW_UP) \n",
    "tm_rng.click()\n",
    "\n",
    "# download\n",
    "# driver.find_element_by_class_name(\"button\").click()\n",
    "driver.find_element(By.CLASS_NAME, \"button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'C:\\Users\\GisselleMaira\\Downloads'\n",
    "file_type = '\\*csv'\n",
    "files = glob.glob(folder_path + file_type)\n",
    "max_file = max(files, key=os.path.getctime)\n",
    "#print (max_file)\n",
    "\n",
    "# folder_path2 = r'C:\\Users\\GisselleMaira\\Desktop'\n",
    "proj_file = folder_path2 + '\\\\project_weekly2.csv'\n",
    "\n",
    "shutil.move(max_file, proj_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle the forecast data to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_wk = pd.read_csv (r'C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\DashboardData\\project_weekly2.csv')\n",
    "\n",
    "col_to_move1 = proj_wk.columns.tolist()[7:]\n",
    "projectW_ = pd.melt(proj_wk, id_vars=['Client', 'Project', 'Person', 'Roles'], value_vars= col_to_move1, value_name='Hours')\n",
    "\n",
    "projectW_.rename(columns= {'variable': 'month', 'Hours': 'Forecast', 'Client': 'client_name',\\\n",
    "                         'Project':'project_name', 'Person': 'user_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "today = date.today()\n",
    "this_wk  = today + datetime.timedelta(days=-today.weekday())\n",
    "\n",
    "# get future weeks of current month\n",
    "projectW_['month'] = pd.to_datetime(projectW_['month']).dt.date\n",
    "projectW_ = projectW_.loc[(projectW_.month >= this_wk)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### weekly forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "projectW_.rename(columns = {'month':'week'}, inplace=True)\n",
    "projectW_['month'] = this_wk.replace(day=1)\n",
    "\n",
    "This_month = this_wk.replace(day=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "proj_wk2 = pd.read_csv(r'C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\DashboardData\\project_weekly2.csv')\n",
    "\n",
    "col_to_move1 = proj_wk2.columns.tolist()[7:]\n",
    "projectW2_ = pd.melt(proj_wk2,\n",
    "                     id_vars=['Client', 'Project', 'Person', 'Roles'],\n",
    "                     value_vars=col_to_move1,\n",
    "                     value_name='Hours')\n",
    "\n",
    "projectW2_.rename(columns= {'variable': 'week', 'Hours': 'Forecast', 'Client': 'client_name',\\\n",
    "                         'Project':'project_name', 'Person': 'user_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "projectW2_['Roles'] = projectW2_['Roles'].replace(\n",
    "    ['Consultant, Data and Analytics, Flying Phase'],\n",
    "    'Consultant, Data and Analytics')\n",
    "\n",
    "projectW2_.loc[projectW2_.user_name == 'Stephanie Lennon',\n",
    "               'Roles'] = 'Principal, Data and Analytics'\n",
    "\n",
    "projectW2_['role'] = projectW2_['Roles'].str.split(',', expand=True)[0]\n",
    "projectW2_['BusUnit'] = projectW2_['Roles'].str.split(',', expand=True)[1]\n",
    "# projectW2_.drop('Roles', 1, inplace=True)\n",
    "\n",
    "rates = time_entries.drop_duplicates([\n",
    "    'project_name', 'project_code', 'client_name', 'user_name', 'hourly_rate', 'billable'\n",
    "])[['project_name', 'project_code', 'client_name','user_name', 'hourly_rate', 'billable']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "forecast3 = pd.merge(projectW2_,\n",
    "                     rates,\n",
    "                     on=['project_name', 'user_name'],\n",
    "                     how='left')\n",
    "\n",
    "forecast3.rename(columns={'client_name_x': 'client_name'}, inplace=True)\n",
    "# forecast3.head(2)\n",
    "rates_stand = rates.loc[\n",
    "    rates.billable == True,\n",
    "    ['user_name', 'client_name', 'hourly_rate']].sort_values('user_name')\n",
    "\n",
    "rates_stand = rates_stand.loc[rates_stand.user_name.notnull()].groupby(\n",
    "    'user_name').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# forecast3.loc[forecast3.billable.isnull()]\n",
    "mask1 = forecast3.client_name != '0000_Spinnaker'\n",
    "mask2 = forecast3.billable.isnull()\n",
    "\n",
    "missing_rates = forecast3.loc[mask1 & mask2].drop_duplicates(\n",
    "    ['user_name', 'project_name',\n",
    "     'client_name'])[['user_name', 'project_name', 'client_name']]\n",
    "\n",
    "missing_rates = pd.merge(missing_rates,\n",
    "                         rates_stand,\n",
    "                         on=['user_name', 'client_name'],\n",
    "                         how='left')\n",
    "\n",
    "rates2 = rates.loc[:,\n",
    "                   ['client_name', 'project_name', 'project_code', 'billable'\n",
    "                    ]].drop_duplicates()\n",
    "\n",
    "missing_rates2 = pd.merge(missing_rates,\n",
    "                          rates2,\n",
    "                          on=['client_name', 'project_name'],\n",
    "                          how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# forecast4 is at weekly level\n",
    "forecast4 = pd.merge(forecast3,\n",
    "                     missing_rates2,\n",
    "                     on=['user_name', 'project_name', 'client_name'],\n",
    "                     how='left')\n",
    "# forecast4.loc[forecast4.user_name == 'Kevin Baquero']\n",
    "\n",
    "forecast4['billable'] = forecast4['billable_x'].fillna(forecast4.billable_y)\n",
    "\n",
    "forecast4 = forecast4.assign(\n",
    "    project_code=forecast4.project_code_x.fillna(forecast4.project_code_y),\n",
    "    hourly_rate=forecast4.hourly_rate_x.fillna(forecast4.hourly_rate_y),\n",
    "    billable=forecast4.billable_x.fillna(forecast4.billable_y))\n",
    "\n",
    "forecast4.loc[forecast4.client_name == '0000_Spinnaker', 'billable'] = False\n",
    "\n",
    "forecast4 = forecast4.assign(month='',\n",
    "                 hours='',\n",
    "                 billable_amt=forecast4.Forecast * forecast4.hourly_rate,\n",
    "                 task_name='',\n",
    "                 invoice_num='',\n",
    "                 invoice_amt='',\n",
    "                 discount_amount='',\n",
    "                 subject='',\n",
    "                 state='forecast',\n",
    "                 issue_date='',\n",
    "                 services_provided='',\n",
    "                 description='')\n",
    "\n",
    "forecast4 = forecast4[[\n",
    "    'client_name', 'project_name', 'project_code', 'week', 'user_name',\n",
    "    'Forecast', 'hourly_rate', 'billable', 'role', 'BusUnit', 'task_name',\n",
    "    'invoice_num', 'invoice_amt', 'discount_amount', 'subject', 'state',\n",
    "    'issue_date', 'services_provided', 'description'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Flat Fees Weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add rows for monthly flat fees with anon user_name and remove other billable amts\n",
    "# this is only for current projects with Flat Fee structure\n",
    "FlatFee = pd.read_excel (r'C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\DashboardData\\FlatFees.xlsx')\n",
    "\n",
    "# create monthly days and combine\n",
    "full_cal = pd.read_excel (r'C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\DashboardData\\Calendar.xlsx')\n",
    "cal_month = full_cal.groupby('Month')['days'].sum()\n",
    "cal_week = full_cal.groupby('Wk_start')['days'].sum()\n",
    "full_cal = full_cal.set_index('dates')\n",
    "# dates2 = pd.merge(dates, cal_month, left_on='Start', right_on ='Month', how='left')\n",
    "\n",
    "Fees2 = pd.merge(FlatFee,cal_month, left_on= 'month' , right_on = 'Month', how='left')\n",
    "Fees2 = Fees2.assign(daily = Fees2.billable_amt /Fees2.days )[['month', 'daily', 'days', 'project_name', 'client_name', 'BusUnit']]\n",
    "\n",
    "FF_projs = list(set(FlatFee['project_name']))\n",
    "FF_projs2 = pd.DataFrame(list(enumerate(FF_projs,1)))\n",
    "FF_projs3 = \"FF\" +  FF_projs2.astype(str)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get weeks broken by month days\n",
    "Fees3 = pd.merge(full_cal.groupby(['Wk_start', 'Month'],\n",
    "                                  as_index=False)['days'].sum(),\n",
    "                 Fees2,\n",
    "                 left_on='Month',\n",
    "                 right_on='month',\n",
    "                 suffixes=['_wkly', '_mnthly'])\n",
    "\n",
    "Fees3 = Fees3.assign(weekly=Fees3.daily * Fees3.days_wkly).drop(\n",
    "    ['Month', 'daily', 'days_mnthly'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Fees4 = Fees3[['client_name', 'project_name', 'Wk_start', 'weekly',\n",
    "               'month', 'BusUnit']].rename({\n",
    "                   'Wk_start': 'week',\n",
    "                   'weekly': 'billable_amt'\n",
    "               },\n",
    "                                axis=1)\n",
    "# Fees3\n",
    "Fees4 = Fees4.assign(billable=True, state='projection')\n",
    "\n",
    "Fees4['week'] = pd.to_datetime(Fees4['week']).dt.date\n",
    "\n",
    "FeesW = pd.merge(Fees4,\n",
    "                 FlatFee.head(1)[['project_name', 'project_code']],\n",
    "                 on='project_name',\n",
    "                 how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# timesheet['week'] = timesheet['spent_date'].dt.to_period('W').apply(lambda x: x.start_time)\n",
    "timesheetW = timesheet.groupby([\n",
    "    'user_name', 'client_name', 'project_name', 'project_code', 'hourly_rate',\n",
    "    'role', 'BusUnit', 'wk_start', 'billable_amt', 'state'\n",
    "]).sum().reset_index()[[\n",
    "    'user_name', 'client_name', 'project_name', 'project_code', 'hourly_rate',\n",
    "    'role', 'BusUnit', 'wk_start', 'billable_amt', 'state', 'hours'\n",
    "]]\n",
    "\n",
    "# get billable tags by project for missing items\n",
    "projs = timesheet.drop_duplicates(['project_name',\n",
    "                           'billable'])[['project_name', 'billable'\n",
    "                                         ]].sort_values('project_name')\n",
    "\n",
    "timesheetW = pd.merge(timesheetW, projs, on='project_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FeesW = FeesW.groupby([\n",
    "    'client_name', 'project_name', 'project_code', 'week', 'billable', 'state', 'BusUnit'\n",
    "]).sum().reset_index()\n",
    "FeesW['week'] = pd.to_datetime(FeesW['week'])\n",
    "Fees_W = FeesW.rename({'week': 'wk_start'}, axis=1)\n",
    "\n",
    "# combine time entries with projected projects\n",
    "weekly_time = pd.concat([Fees_W, timesheetW], axis=0)\n",
    "\n",
    "# remove billable_amt for flat fee projects\n",
    "weekly_time.loc[ (weekly_time.state == 'time_entries') &  (weekly_time.project_name.isin(FF_projs)), 'billable_amt'] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "forecast5 = forecast4[[\n",
    "    'client_name', 'project_name', 'week', 'billable', 'state', 'project_code',\n",
    "    'user_name', 'hourly_rate', 'role', 'BusUnit', 'Forecast'\n",
    "]].rename({'week': 'wk_start'}, axis=1)\n",
    "\n",
    "forecast5['billable_amt'] = np.where(\n",
    "    forecast5.project_name.isin(FF_projs), 0,\n",
    "    forecast5.Forecast * forecast5.hourly_rate)\n",
    "forecastW = pd.concat([weekly_time, forecast5], axis=0)\n",
    "\n",
    "forecastW['T_hours'] = forecastW['Forecast'].fillna(0) + forecastW['hours'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forecastW2 = forecastW.loc[forecastW.billable == True, [\n",
    "    'project_name', 'wk_start', 'state', 'role', 'BusUnit', 'billable_amt'\n",
    "]]\n",
    "\n",
    "# forecastW2.groupby(['project_name', 'wk_start', 'state', 'role', 'BusUnit']).sum().reset_index()\n",
    "\n",
    "forecastW2['wk_start'] = pd.to_datetime(forecastW2['wk_start'])\n",
    "forecastW2.set_index('wk_start')\n",
    "\n",
    "forecastW3 = forecastW2.loc[forecastW2.wk_start >= '2022-01-03'].groupby(['wk_start']).sum().round(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wk_proj = pd.concat([forecastW3, forecastW3.cumsum(axis=0).rename({'billable_amt':'cume'}, axis=1)], axis=1)\n",
    "\n",
    "wk_proj = wk_proj.assign(remaining = 2500000 - wk_proj['cume']).reset_index()\n",
    "\n",
    "end_date = datetime.date(2022, 6, 30)\n",
    "end_date_wk= (end_date - datetime.timedelta(days=end_date.weekday()))\n",
    "\n",
    "def diff(start, end):\n",
    "    x = pd.to_datetime(end) - pd.to_datetime(start)\n",
    "    return int(x / np.timedelta64(1, 'W'))\n",
    "\n",
    "wk_proj['weeks_left'] = wk_proj['wk_start'].apply(lambda x: diff(x,end_date_wk))\n",
    "wk_proj = wk_proj.assign(needed = wk_proj['remaining'] / wk_proj['weeks_left'])\n",
    "wk_proj = wk_proj.assign(wk_new = wk_proj.wk_start.dt.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "needed = wk_proj.loc[wk_proj.wk_new == this_wk, 'needed']\n",
    "\n",
    "after_curr = [x >= this_wk for x in wk_proj.wk_new]\n",
    "\n",
    "wk_proj['wk_goal'] = np.where(after_curr, int(needed), 0)\n",
    "\n",
    "wk_proj2 = wk_proj[['wk_start', 'billable_amt', 'cume', 'wk_goal']]\n",
    "\n",
    "wk_proj2.to_excel(\n",
    "    r'C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\DashboardData\\weekly.xlsx',\n",
    "    index=False)\n",
    "Archive('weekly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monthly forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_mnth = pd.read_csv(\n",
    "    r'C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\DashboardData\\project_monthly.csv'\n",
    ")\n",
    "col_to_move2 = proj_mnth.columns.tolist()[7:]\n",
    "\n",
    "projectM_ = pd.melt(proj_mnth,\n",
    "                    id_vars=['Client', 'Project', 'Person', 'Roles'],\n",
    "                    \n",
    "                    value_vars=col_to_move2,\n",
    "                    value_name='Hours')\n",
    "projectM_ = projectM_[projectM_['Hours'] > 0]\n",
    "\n",
    "projectM_.rename(columns= {'variable': 'month', 'Hours': 'Forecast', 'Client': 'client_name',\\\n",
    "                         'Project':'project_name', 'Person': 'user_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create forecast with future months and future weeks in current month\n",
    "This_month = pd.to_datetime(This_month)\n",
    "\n",
    "projectM_.month = pd.to_datetime(projectM_.month)\n",
    "projectW_.month = pd.to_datetime(projectW_.month)\n",
    "\n",
    "projectM_ = projectM_.loc[(projectM_['month'] != This_month)]\n",
    "# projectW_.drop(['week'],1, inplace=True)\n",
    "\n",
    "forecast = pd.concat([projectW_,projectM_], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast['Roles'] = forecast['Roles'].replace(\n",
    "    ['Consultant, Data and Analytics, Flying Phase'],\n",
    "    'Consultant, Data and Analytics')\n",
    "\n",
    "forecast.loc[forecast.user_name == 'Stephanie Lennon', 'Roles'] = 'Principal, Data and Analytics'\n",
    "\n",
    "forecast['role'] = forecast['Roles'].str.split(',', expand=True)[0]\n",
    "forecast['BusUnit'] = forecast['Roles'].str.split(',', expand=True)[1]\n",
    "forecast.drop('Roles', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "# monthly needed for specific reports\n",
    "forecast2 = pd.merge(forecast, rates, on=['project_name', 'user_name', 'client_name'])\n",
    "forecast2['billable_amt'] = forecast2.hourly_rate * forecast2.Forecast\n",
    "\n",
    "forecast2 = forecast2.assign(hours=0,\n",
    "                             task_name='',\n",
    "                             invoice_num='',\n",
    "                             invoice_amt='',\n",
    "                             discount_amount='',\n",
    "                             subject='',\n",
    "                             state='forecast',\n",
    "                             issue_date='',\n",
    "                             services_provided='',\n",
    "                             description='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fees2 provides flat fee revenue structure by month, remove past month(s)\n",
    "FFprojects = Fees2.project_name.unique()\n",
    "\n",
    "# eliminate billable amt for fixed fee projects\n",
    "forecast2.loc[forecast2.project_name.isin(FFprojects), 'billable_amt'] = 0\n",
    "forecast2 = forecast2.assign(FF = np.where(forecast2.project_name.isin(FFprojects),1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_dt = '2022-' + str(datetime.datetime.today().month) + '-1'\n",
    "\n",
    "Fees5 = Fees2.assign(billable=True,\n",
    "                     billable_amt=Fees2['daily'] * Fees2['days'],\n",
    "                     state='projection').drop(['daily', 'days'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fees5 = Fees5.loc[Fees5.month >= filter_dt]\n",
    "\n",
    "# merge fixed fee with \n",
    "forecastM = pd.concat([Fees5, forecast2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Get all invoices and first project_name to fill in gaps\n",
    "names = time_entries.drop_duplicates(subset='invoice_num')[['invoice_num', 'project_name', 'project_code']]\n",
    "time_entries_merge = pd.merge(time_entries, names, on='invoice_num', how='left')\n",
    "\n",
    "time_entries_merge = time_entries_merge.assign(\n",
    "    project_name=np.where(time_entries_merge.project_name_x.isnull(),\n",
    "                          time_entries_merge.project_name_y,\n",
    "                          time_entries_merge.project_name_x),\n",
    "    project_code=np.where(time_entries_merge.project_code_x.isnull(),\n",
    "                          time_entries_merge.project_code_y,\n",
    "                          time_entries_merge.project_code_x)).drop([\n",
    "                              'project_name_y', 'project_code_y',\n",
    "                              'project_name_x', 'project_code_x'\n",
    "                          ], 1)\n",
    "\n",
    "time_entries_merge['user_name'] = time_entries_merge['user_name'].str.strip()\n",
    "time_entries_fix = pd.merge(time_entries_merge,\n",
    "                            rate_card,\n",
    "                            on=['user_name', 'project_name', 'hourly_rate'],\n",
    "                            how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all = pd.concat([time_entries_fix, forecastM])[[ 'client_name', 'project_name', 'project_code', 'month', 'hours',\n",
    "    'hourly_rate', 'billable_amt', 'billable', 'role', 'BusUnit',\n",
    "    'invoice_num', 'invoice_amt', 'state', 'description']]\n",
    "\n",
    "# alltime_entries.fillna({'Forecast':0, 'hours':0, 'FF': 0}, inplace=True)\n",
    "# monthly = alltime_entries[[\n",
    "#     'client_name', 'project_name', 'project_code', 'month', 'hours',\n",
    "#     'hourly_rate', 'billable_amt', 'billable', 'role', 'BusUnit',\n",
    "#     'invoice_num', 'invoice_amt', 'state', 'description', 'Forecast', 'FF'\n",
    "# ]]\n",
    "\n",
    "all.to_excel(\n",
    "    r'C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\DashboardData\\monthly.xlsx',\n",
    "    index=False)\n",
    "\n",
    "Archive('monthly')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRM refresh or Sharepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "option = Options()\n",
    "\n",
    "option.add_argument(\"--disable-infobars\")\n",
    "option.add_argument(\"start-maximized\")\n",
    "option.add_argument(\"--disable-extensions\")\n",
    "\n",
    "# Pass the argument 1 to allow and 2 to block\n",
    "option.add_experimental_option(\"prefs\", { \n",
    "    \"profile.default_content_setting_values.notifications\": 2 \n",
    "})\n",
    "\n",
    "driver = webdriver.Chrome(options=option)\n",
    "# driver = webdriver.Chrome(chrome_options=option, executable_path='path-of-driver\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape forecast data from Harvest Forecast\n",
    "config = configparser.ConfigParser()\n",
    "config.read(r'C:\\Users\\GisselleMaira\\test.ini')\n",
    "\n",
    "user = config['Zoho']['email2']\n",
    "pswd = config['Zoho']['pswd2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2)\n",
    "driver.get(\"https://accounts.zoho.com/signin\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "email = driver.find_element(By.ID, \"login_id\")\n",
    "email.click()\n",
    "email.send_keys(user)\n",
    "\n",
    "driver.find_element(By.ID, \"nextbtn\").click()\n",
    "time.sleep(2)\n",
    "\n",
    "pwd = driver.find_element(By.ID, \"password\")\n",
    "pwd.send_keys(pswd)\n",
    "\n",
    "driver.find_element(By.ID, \"nextbtn\").click()\n",
    "time.sleep(2)\n",
    "\n",
    "driver.get('https://crm.zoho.com/crm/org771208238/settings/export-data')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2)\n",
    "\n",
    "sel = Select(driver.find_element_by_xpath(\"//select[@name='module']\"))\n",
    "sel.select_by_visible_text('Deals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.ID, \"Submit\").click()\n",
    "driver.switch_to.alert.accept()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_file():\n",
    "    ''' moves last downloaded file to saved subfolder'''\n",
    "    folder_path = r'C:\\Users\\GisselleMaira\\Downloads'\n",
    "    file_type = '\\*csv'\n",
    "    files = glob.glob(folder_path + file_type)\n",
    "    max_file = max(files, key=os.path.getctime)\n",
    "    shutil.move(max_file, proj_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path2 = r'C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\DashboardData'\n",
    "proj_file = folder_path2 + '\\\\ZohoDeals.csv'\n",
    "\n",
    "move_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Opps (weekly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "deals = pd.read_csv (r'C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\DashboardData\\ZohoDeals.csv')\n",
    "\n",
    "today = date.today()\n",
    "latest_wk = today - timedelta(today.weekday()+ 1)\n",
    "prior_wk = latest_wk - datetime.timedelta(days=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deals = deals.rename({'Probability (%)': 'Prob'}, axis=1)[[\n",
    "    'Deal Owner', 'Amount', 'Expected Revenue', 'Deal Name', 'Account Name',\n",
    "    'Stage', 'Created Time', 'Modified Time', 'Proposal Type',\n",
    "    'Expected Start Date', 'Expected End Date', 'Nature of Work', 'Prob'\n",
    "]]\n",
    "\n",
    "cols = [\n",
    "    'Created Time', 'Expected Start Date', 'Expected End Date', 'Modified Time'\n",
    "]\n",
    "deals[cols] = deals[cols].apply(pd.to_datetime)\n",
    "\n",
    "deals.rename(\n",
    "    {\n",
    "        'Expected Start Date': 'start',\n",
    "        'Expected End Date': 'end',\n",
    "        'Created Time': 'Created',\n",
    "        'Modified Time': 'Modified'\n",
    "    },\n",
    "    axis=1,\n",
    "    inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Won = deals.loc[(deals.Prob > 50)\n",
    "                & (deals.Stage == 'Closed Won - Land & Expand') &\n",
    "                (deals.start.notnull()) & (deals.start > filter_dt)]\n",
    "\n",
    "Pending = deals.loc[(deals.Prob > 50) & (~deals['Stage'].str.contains('Closed')) &\n",
    "          (deals.start.notnull()) & (deals.start > filter_dt)]\n",
    "\n",
    "all_projs = pd.concat([Won, Pending], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Won"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create generic table for dates\n",
    "today = date.today()\n",
    "tgt = datetime.date(2022, 1, 1)\n",
    "next_6month = today + relativedelta(months=7)\n",
    "\n",
    "# # start/end dates for each month\n",
    "M_start = pd.date_range(tgt, next_6month,freq='MS')\n",
    "M_end = pd.date_range(tgt, next_6month,freq='M')\n",
    "dates = pd.DataFrame(list(zip(M_start, M_end)), columns =['Start', 'End'])\n",
    "dates['Month'] = dates['Start'].dt.strftime('%Y-%m')\n",
    "\n",
    "# create monthly days and combine\n",
    "full_cal = pd.read_excel (r'C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\DashboardData\\Calendar.xlsx')\n",
    "cal_month = full_cal.groupby('Month')['days'].sum()\n",
    "dates2 = pd.merge(dates, cal_month, left_on='Start', right_on ='Month', how='left')\n",
    "\n",
    "full_cal = full_cal.set_index('dates')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace empty dates with placeholders \n",
    "# nodate = datetime.datetime(2099, 1, 1)\n",
    "# nodate2 = datetime.datetime(2099, 1, 1)\n",
    "\n",
    "# Probable['start'].fillna(nodate, inplace = True)\n",
    "# Probable['end'].fillna(nodate2, inplace = True)\n",
    "\n",
    "# create holiday file\n",
    "us_hol_date = []\n",
    "us_hol_name = []\n",
    "\n",
    "comp_holidays = [\"New Year's Day\",\n",
    "                 \"Martin Luther King Jr. Day\",\n",
    "                 \"Washington's Birthday\",\n",
    "                 'Memorial Day',\n",
    "                 'Independence Day',\n",
    "                 'Labor Day', \n",
    "                 'Thanksgiving', \n",
    "                 'Christmas Day']\n",
    "for day, name in holidays.US(years=[2022, 2023], observed=True).items():\n",
    "    if name in comp_holidays:\n",
    "        us_hol_name.append(name)\n",
    "        us_hol_date.append(day)\n",
    "maskcal=np.busdaycalendar(holidays=us_hol_date)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc busdays and daily revs\n",
    "all_projs = all_projs.assign(\n",
    "    diff_days=np.busday_count(all_projs['start'].values.astype('datetime64[D]'),\n",
    "                              all_projs['end'].values.astype('datetime64[D]'),\n",
    "                              busdaycal=maskcal))\n",
    "\n",
    "all_projs = all_projs.assign(daily = all_projs['Expected Revenue']/all_projs['diff_days'])\n",
    "\n",
    "all_projs = all_projs.loc[all_projs.start > pd.to_datetime(today)]\n",
    "\n",
    "# all_projs\n",
    "# NewRevs = Probable.loc[Probable.diff_days > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes per project and combine\n",
    "newP = []\n",
    "for i in range(len(all_projs)):\n",
    "    new = dates2.loc[(all_projs['start'].iloc[i] <= dates2.End)\n",
    "                     & (all_projs['end'].iloc[i] >= dates2.Start)].assign(\n",
    "                         project=all_projs['Deal Name'].iloc[i],\n",
    "                         owner=all_projs['Deal Owner'].iloc[i],\n",
    "                         Client=all_projs['Account Name'].iloc[i],\n",
    "                         stage=all_projs['Stage'].iloc[i],\n",
    "                         daily=all_projs['daily'].iloc[i],\n",
    "                         start=all_projs['start'].iloc[i],\n",
    "                         end=all_projs['end'].iloc[i])\n",
    "    newP.append(new)\n",
    "new = pd.concat(newP)\n",
    "\n",
    "# replace start/end dates with project start/end dates as approp\n",
    "new = new.assign(\n",
    "    NewStart=np.where(new['Start'] > new['start'], new['Start'], new['start']),\n",
    "    NewEnd=np.where(new['End'] < new['end'], new['End'],\n",
    "                    new['end'])).drop(['Start', 'End', 'start', 'end', 'days'], axis=1)\n",
    "\n",
    "# check for in progress projects\n",
    "# Last_fri = date.today() + timedelta(days=-today.weekday()) + timedelta(days=4)\n",
    "# new.loc[new.NewStart < pd.to_datetime(today), 'NewStart'] = Last_fri\n",
    "# all.loc[all.client_name.str.contains('Hard'),['project_name', 'state', 'month']]\n",
    "\n",
    "# get busdays\n",
    "new = new.assign(\n",
    "    diff_days=np.busday_count(new['NewStart'].values.astype('datetime64[D]'),\n",
    "                              new['NewEnd'].values.astype('datetime64[D]'),\n",
    "                              busdaycal=maskcal))\n",
    "\n",
    "new = new.assign(Revenue = new.diff_days * new.daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new2 = new.rename(columns={\n",
    "    'Client': 'client_name',\n",
    "    'project': 'project_name',\n",
    "    'Revenue': 'billable_amt'\n",
    "}).assign(billable=True,\n",
    "          state='NewProject',\n",
    "          project_code='Prospective Project').drop(\n",
    "              ['daily', 'NewStart', 'NewEnd', 'diff_days'], axis=1)\n",
    "\n",
    "# convert mo-yr to trunc date\n",
    "new2.Month = pd.to_datetime(new2.Month)\n",
    "new2 = new2.rename(columns={'Month': 'month'})\n",
    "\n",
    "new2['client_name'] = 'ZProspective_' + new2['client_name'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all = all.assign(Type = 'Current')\n",
    "new2 = new2.assign(Type='New')\n",
    "\n",
    "final = pd.concat([all, new2], axis=0)\n",
    "final2 = final.drop_duplicates()\n",
    "final2.loc[(final2.project_name.isin(FF_projs)) & (final2.state == 'time_entries'), 'billable_amt'] = 0\n",
    "# final2.loc[(final2.project_name.isin(FF_projs)) & (final2.state == 'time_entries')]\n",
    "final2.loc[(final2.project_name.isin(FF_projs)) & (final2.month == '2022-03-01') & (final2.state == 'projection'), 'billable_amt'] = 0 \n",
    "\n",
    "\n",
    "final2.BusUnit = final2.BusUnit.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final3 = final2.assign(order=np.where(final2.Type == 'Current', 1, 4))\n",
    "\n",
    "CurrProj = final3.loc[final3.Type == 'Current'].groupby(['month']).sum()[[\n",
    "    'billable_amt'\n",
    "]].assign(order=2, project_name='All Current Projects').reset_index()\n",
    "\n",
    "CurrProj_noFP = final3.loc[\n",
    "    (final3.Type == 'Current')\n",
    "    & (final3.BusUnit != 'Flying Phase')].groupby(['month']).sum()[[\n",
    "        'billable_amt'\n",
    "    ]].assign(order=2, project_name='All Current Projects w/o FP').reset_index()\n",
    "\n",
    "subtotal_New = final3.loc[final3.Type == 'New'].groupby([\n",
    "    'month', 'Type'\n",
    "]).sum()[['billable_amt']].assign(order=5,\n",
    "                                  project_name='All Prospective Projects',\n",
    "                                  state='all').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_ttls = final3.groupby('month').sum()[['billable_amt']].assign(\n",
    "    project_name='All Projects', state='all', Type='all',\n",
    "    order=6).reset_index()\n",
    "\n",
    "month_ttls_woFP = final3.loc[final3.BusUnit != 'Flying Phase'].groupby('month').sum()[[\n",
    "    'billable_amt'\n",
    "]].assign(project_name='All Projects w/o FP', state='all', Type = 'all',\n",
    "          order=7).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = pd.concat([CurrProjAll, CurrProj_noFP, subtotal_New, month_ttls, month_ttls_woFP])\n",
    "final4 = pd.concat([final3, totals])\n",
    "final4 = final4.drop_duplicates()\n",
    "\n",
    "# pd.to_datetime(totals['month']).dt.floor('d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final4.to_excel(r\"C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\DashboardData\\forecast3.xlsx\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttl_join = pd.merge(\n",
    "#     month_ttls.drop(['BusUnit', 'state', 'order', 'project_name'], 1),\n",
    "#     FP_ttls.drop(['BusUnit', 'state', 'order', 'project_name'], 1),\n",
    "#     on='month')\n",
    "\n",
    "# ttl_join = ttl_join.assign(billable_amt=ttl_join.billable_amt_x -\n",
    "#                            ttl_join.billable_amt_y,\n",
    "#                            state='total',\n",
    "#                            order=4,\n",
    "#                            project_name='All Projects excl FP').drop(\n",
    "#                                ['billable_amt_x', 'billable_amt_y'], 1)\n",
    "\n",
    "# final2 = final2.assign(order = 1)\n",
    "\n",
    "# final3 = pd.concat([final2, month_ttls, FP_ttls, ttl_join], axis=0)\n",
    "\n",
    "# final3 = final3[['order', 'client_name', 'project_name', 'project_code', 'month', 'hours',\n",
    "#        'hourly_rate', 'billable_amt', 'billable', 'role', 'BusUnit',\n",
    "#        'invoice_num', 'invoice_amt', 'state', 'description', 'owner', 'stage']]\n",
    "\n",
    "# final3.to_excel(r\"C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\DashboardData\\forecast2.xlsx\", index=False) \n",
    "\n",
    "# final3[['order', 'client_name', 'project_name', 'project_code', 'month', 'hours',\n",
    "#        'hourly_rate', 'billable_amt', 'billable', 'role', 'BusUnit',\n",
    "#        'invoice_num', 'invoice_amt', 'state', 'description', 'owner', 'stage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prospects['Expected Start Date']\n",
    "\n",
    "# proj_len = []\n",
    "# for i in range(len(Prospects)):\n",
    "#     proj_len.append(full_cal.loc[\n",
    "#         (full_cal.index >= pd.DatetimeIndex(Prospects['Expected Start Date'])[i]) ,\n",
    "# #         &\n",
    "# #         (full_cal.index <= pd.DatetimeIndex(Prospects['Project End'])[i]),\n",
    "#         'days'].sum())    \n",
    "\n",
    "# rpt['daily'] = pd.to_numeric(rpt['Project Budget'].str.replace(',', ''),\n",
    "#                              errors='coerce') / proj_len\n",
    "\n",
    "# fnl_forecast = pd.concat([alltime_entries,prospects], axis=0)\n",
    "\n",
    "# fnl_forecast.to_excel(r\"C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\DashboardData\\forecast.xlsx\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emp Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull start/end (term) dates from file and generate datelist\n",
    "edates = pd.read_excel(\n",
    "    r'C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\SeniorityReport.xlsx')\n",
    "\n",
    "edates['user_name'] = edates['Preferred/First Name'] + ' ' + edates['Last Name']\n",
    "edates.drop([\n",
    "    'Last Name', 'Preferred/First Name', 'Tenure (In English)',\n",
    "    'Tenure (in Months)'\n",
    "],\n",
    "           1,\n",
    "           inplace=True)\n",
    "active = datetime.datetime(2025, 1, 1)\n",
    "edates[\"Termination Date\"].fillna(active, inplace = True)\n",
    "\n",
    "\n",
    "#generate dataset for 18 weeks \n",
    "today = date.today()\n",
    "this_wk = today + timedelta(days=-today.weekday(), weeks=0)\n",
    "start = today + timedelta(days=-today.weekday(), weeks=-16)\n",
    "\n",
    "# empty date range\n",
    "datelist = pd.date_range(start=start, periods=18, freq='W-MON').tolist()\n",
    "# datelist2 = pd.date_range(start = start, periods = 13, freq='W-SUN').tolist()\n",
    "newdates = [d.strftime('%m-%d-%Y') for d in datelist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross join sets and add active indicators\n",
    "newdates = pd.DataFrame(newdates, columns=['date'])\n",
    "newdates['key'] = 1\n",
    "edates['key'] = 1\n",
    "\n",
    "edates2 = pd.merge(edates, newdates, on='key',\n",
    "                   how='outer').drop('key', 1).rename(columns={\n",
    "                       'Termination Date': 'end',\n",
    "                       'Hire Date': 'Hire'\n",
    "                   })\n",
    "\n",
    "edates2['date'] = pd.to_datetime(edates2['date'])\n",
    "# edates2.dtypes\n",
    "\n",
    "edates2 = edates2.assign(\n",
    "    Active=np.where((edates2['Hire'] <= edates2['date'])\n",
    "                    & (edates2['end'] >= edates2['date']), 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get role/busUnit from API data\n",
    "users_3 = users3.copy()\n",
    "\n",
    "# drop Flying Phase from dual BusUnit consultants\n",
    "ind = users_3.loc[\n",
    "    (users_3['user_name'].isin(['Parker Barouch', 'Kevin Baquero']))\n",
    "    & (users_3['BusUnit'] == 'Flying Phase')].index\n",
    "\n",
    "users_3.drop(ind, inplace=True)\n",
    "\n",
    "users_3 = users_3.drop_duplicates()\n",
    "\n",
    "empcounts = pd.merge(edates2, users_3, on='user_name', how='left')\n",
    "empcounts2 = empcounts.loc[empcounts.Active == 1,\n",
    "              ['user_name', 'role', 'BusUnit', 'date', 'Active']].rename(\n",
    "                  columns={'date': 'wk_start'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with time entries l4M\n",
    "time_2 = assign_merge.copy()\n",
    "\n",
    "time_2['spent_date'] = pd.to_datetime(time_2['spent_date']) \n",
    "time_2['wk_start'] = time_2['spent_date'] - pd.TimedeltaIndex(time_2.spent_date.dt.dayofweek,unit='d') \n",
    "time_2 = time_2[['wk_start', 'user_name','billable', 'rounded_hours', 'project_name','task_name']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_bill = time_2.loc[time_2.billable == True].groupby(\n",
    "    ['wk_start', 'user_name', 'billable', 'project_name',\n",
    "     'task_name']).sum().reset_index().drop(['billable', 'task_name'], 1)\n",
    "\n",
    "times_bill = times_bill.loc[(times_bill.wk_start < pd.to_datetime(this_wk))\n",
    "                            & (times_bill.wk_start >= pd.to_datetime(start))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_bill.to_excel( r'C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\DashboardData\\empcount_billed.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create summary tables\n",
    "hrs = time_2.groupby(['wk_start', 'user_name', 'billable']).sum().reset_index()\n",
    "hrs = hrs.assign(Type = np.where(hrs.billable == True, 'Bill Hrs', 'Nonbill Hrs')).drop('billable',1)\n",
    "\n",
    "hrs2 = hrs.pivot(index=['wk_start', 'user_name'], columns = 'Type',values='rounded_hours' ).reset_index()\n",
    "hrs2 = hrs2.fillna({'Bill Hrs':np.nan, 'Nonbill Hrs':np.nan}).fillna(0)\n",
    "hrs2 = hrs2.assign(Total = hrs2['Bill Hrs']+ hrs2['Nonbill Hrs'])\n",
    "hrs2 = hrs2.loc[(hrs2.wk_start < pd.to_datetime(this_wk)) & (hrs2.wk_start >= pd.to_datetime(start)) ]\n",
    "\n",
    "active_hrs = pd.merge(empcounts2, hrs2, on=['user_name', 'wk_start'],  how='left')\n",
    "# active_hrs.loc[(active_hrs.task_name.isnull()) & (active_hrs.Total.isnull()), 'task_name'] = 'None'\n",
    "active_hrs.loc[(active_hrs.Total.isnull()), 'Total'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes users with no hour or BusUnit\n",
    "active_hrs = active_hrs.loc[(~(active_hrs.Total.isnull()) &\n",
    "                             (active_hrs.BusUnit.isnull())) |\n",
    "                            (active_hrs.BusUnit.notna())]\n",
    "active_hrs.to_excel( r'C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\DashboardData\\empcount.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create detailed view\n",
    "task_hrs = time_2.groupby(['wk_start', 'user_name', 'billable', 'project_name','task_name']).sum().reset_index()\n",
    "\n",
    "categories = pd.read_excel(r'C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\DashboardData\\projects.xlsx')\n",
    "task_hrs2 = pd.merge(task_hrs, categories, how='left', on=['project_name', 'task_name'])\n",
    "task_hrs2.Category = np.where(task_hrs2.Category.isnull() & task_hrs2.billable == True, 'billable', task_hrs2.Category)\n",
    "\n",
    "task_hrs3 = task_hrs2.groupby(['wk_start', 'user_name', 'Category']).sum().reset_index().drop('billable',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empcounts2.loc[empcounts2.user_name == 'Jason Xie']\n",
    "empcounts2['key'] = 1\n",
    "\n",
    "cats = categories.loc[categories.Category.notnull(), 'Category'].unique()\n",
    "cats = np.append(cats, ['billable'], axis=0)\n",
    "cats = pd.DataFrame(cats, columns=['category']).assign(key = 1)\n",
    "\n",
    "# task_hrs3 = pd.merge(task_hrs4.drop(['Category', 'rounded_hours'], 1).drop_duplicates(),\n",
    "#                         cats,\n",
    "#                         on='key',\n",
    "#                         how='outer').rename({'category' : 'Category'}, axis = 1).drop('key',1)\n",
    "\n",
    "task_hrs4 = pd.merge(empcounts2, cats, on='key', how='outer').drop('key', 1).rename({'category': 'Category'}, axis=1)\n",
    "\n",
    "task_hrs5 = pd.merge(task_hrs4, task_hrs3, on = ['user_name', 'wk_start', 'Category'], how='left')\n",
    "task_hrs5['rounded_hours'] = task_hrs5['rounded_hours'].fillna(0)\n",
    "\n",
    "task_hrs5.to_excel( r'C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\DashboardData\\empcount_task.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdates = pd.DataFrame(newdates, columns=['date'])\n",
    "newdates['key'] = 1\n",
    "edates['key'] = 1\n",
    "\n",
    "edates2 = pd.merge(edates, newdates, on='key',\n",
    "                   how='outer').drop('key', 1).rename(columns={\n",
    "                       'Termination Date': 'end',\n",
    "                       'Hire Date': 'Hire'\n",
    "                   })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active2 = active_hrs.loc[active_hrs.Active == 1]\n",
    "active2.loc[active2.user_name.isin([\n",
    "    'Paige Wolk', 'Megan Murray', 'Tristan Andrews', 'Brooke Pray',\n",
    "    'Charles Chareunsy', 'Paul Blodgett', 'Shawn Sweeney'\n",
    "]), 'BusUnit'] = 'Operations'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "projects = assign_merge[['project_name', 'task_name', 'billable']].drop_duplicates()\n",
    "# projects.to_excel( r'C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\DashboardData\\projects.xlsx', index = False)\n",
    "\n",
    "categories = pd.read_excel(r'C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\DashboardData\\projects.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ActiveEmps = active_hrs[['user_name','Active', 'BusUnit' ]].groupby(['user_name', 'BusUnit']).sum()\n",
    "# ActiveEmps.loc[ActiveEmps.Active > 0]\n",
    "\n",
    "# ActiveEmps.loc[ActiveEmps.Active == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_hrs.loc[active_hrs.Total == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_ttl = active_hrs[['wk_start', 'bill_hrs', 'Nonbill_hrs', 'Total', 'role', 'BusUnit']]\n",
    "# active_ttl = active_ttl.groupby(['wk_start', 'role', 'BusUnit']).sum().reset_index()\n",
    "\n",
    "active1 = active_ttl.drop('bill_hrs', 1).groupby(['wk_start', 'role', 'BusUnit']).sum().reset_index()\n",
    "active2 = active_ttl.drop('Nonbill_hrs', 1).groupby(['wk_start', 'role', 'BusUnit']).sum().reset_index()\n",
    "\n",
    "active1['Hr_type'] = 'Nonbilled'\n",
    "active2['Hr_type'] = 'billed'\n",
    "\n",
    "active1.rename(columns = {'Nonbill_hrs': 'hours'}, inplace = True)\n",
    "active2.rename(columns = {'bill_hrs': 'hours'}, inplace = True)\n",
    "\n",
    "active_ttl2 = pd.concat([active1, active2], axis=0)\n",
    "active_ttl2.drop('Total', 1, inplace = True)\n",
    "\n",
    "active_ttl2.to_excel( r'C:\\Users\\GisselleMaira\\Desktop\\SLT Docs\\DashboardData\\empcount2.xlsx', index = False) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 17.5,
   "position": {
    "height": "675.976px",
    "left": "1692.44px",
    "right": "20px",
    "top": "156.992px",
    "width": "559.961px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
